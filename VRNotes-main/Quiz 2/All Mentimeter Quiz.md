# Mentimeter

Covers from Week 8 - 13

This is an attempt to collate all mentimeter questions in one MD

## Week 8
Q1\
Which interaction mechanic is commonly deemed to be the most important in immersive AR, VR and MR experiences?
- Viewport Control
- Hand Gestures
- Body (Excluding hands gestures)
- All mechanics are equally important

<details>
  <summary>Answer</summary>
  Viewport Control
</details>
<br>

This is for Q2, Q3 & Q4\
![VR Bioreactor Training](MentiImages/w8-01.png)

Q2\
In the VR Bioreactor Training system, what interaction mechanics were implemented?
- Viewport Control
- Hand Gestures
- Body (Excluding hands gestures)
- All of the above

<details>
  <summary>Answer</summary>
  Viewport Control
  <br>
  Hand Gestures
</details>
<br>

Q3\
In the VR Bioreactor Training system, is viewport control a passive or active interaction mechanics?
- Passive
- Active

<details>
  <summary>Answer</summary>
  Passive
</details>
<br>

Q4\
In the VR Bioreactor Training system, are hand gestures a passive or active interaction mechanic?
- Passive
- Active

<details>
  <summary>Answer</summary>
  Active
</details>
<br>

This is for Q5, Q6 & Q7\
![360 Video Lecture](MentiImages/w8-02.png)

Q5\
In the 360 Video Lecture, what interaction mechanics were implemented?
- Viewport Control
- Hand Gestures
- Body (Excluding hands gestures)
- All of the above

<details>
  <summary>Answer</summary>
  Viewport Control
  <br>
  Hand Gestures
</details>
<br>

Q6\
In the 360 Video Lecture, is viewport control a passive or active interaction mechanics?
- Passive
- Active

<details>
  <summary>Answer</summary>
  Passive
  <br>
  Active
</details>
<br>

Q7\
In the 360 Video Lecture, what form of interaction authenticity is the eye-gaze point-and-click mechanic?
- Natural interaction
- Artificial magical interaction
- Artificial augmented natural interaction

<details>
  <summary>Answer</summary>
  Artificial augmented natural interaction
</details>
<br>

Q8\
Many users tend to route their hands behind the virtual saw blade when asked to place their hands in the target position? What is the primary reason?
- Limited field of view in the VR headset affecting depth perception
- The saw blade simply looks hyper-realistic
- High embodiment via realistic hand representation and precise tracking
- Difficult in accurately perceiving the virtual saw blade's position

<details>
  <summary>Answer</summary>
  High embodiment via realistic hand representation and precise tracking
</details>
<br>

Q9\
![Wk8 Q9](MentiImages/w8-03.png)\
What interaction authenticity is optimal?
- Natural interaction
- Artificial magical interaction
- Artificial augmented natural interaction

<details>
  <summary>Answer</summary>
  Natural interaction
</details>
<br>

Q10\
![Wk8 Q10](MentiImages/w8-04.png)\
What interaction authenticity is optimal?
- Natural interaction
- Artificial magical interaction
- Artificial augmented natural interaction

<details>
  <summary>Answer</summary>
  Natural interaction
</details>
<br>

Q11\
![Wk8 Q11](MentiImages/w8-05.png)\
Which device platform is the most appropriate here?
- Desktop
- Google Cardboard
- Meta Quest 2 (Wireless)
- HTC Vive Pro (Wired)
- Microsoft Hololens

<details>
  <summary>Answer</summary>
  Meta Quest 2 (Wireless)
</details>
<br>

Q12\
![Wk8 Q12](MentiImages/w8-06.png)\
Which device platform is the most appropriate here?
- Desktop
- Google Cardboard
- Meta Quest 2 (Wireless)
- HTC Vive Pro (Wired)
- Microsoft Hololens

<details>
  <summary>Answer</summary>
  HTC Vive Pro (Wired)
</details>
<br>

Q13\
![Wk8 Q13](MentiImages/w8-07.png)\
What form of GUI implementation is best suited for this use case?
- GUI on a virtual paper (using a virtual pen)
- GUI on a 3D plane anchored in virtual world locations
- Real-world quiz on real paper (take off HMD when interacting)

<details>
  <summary>Answer</summary>
  GUI on a 3D plane anchored in virtual world locations
  <br>
  Real-world quiz on real paper (take off HMD when interacting)
</details>
<br>

Q14\
![Wk8 Q14](MentiImages/w8-08.png)\
What form of GUI implementation is best suited for this use case?
- GUI on a virtual paper (using a virtual pen)
- GUI on a 3D plane anchored in virtual world locations
- Real-world quiz on real paper (take off HMD when interacting)

<details>
  <summary>Answer</summary>
  GUI on a 3D plane anchored in virtual world locations
</details>
<br>

Q15\
![Wk8 Q15](MentiImages/w8-09.png)
- Teleportation
- Joystick-based
- Walking-in-place (WIP) with KatVR 360 slidemill
- Walking-in-place (WIP) with HTC Vive HMD and trackers
- Tracking real movement in physical space

<details>
  <summary>Answer</summary>
  Teleportation
</details>
<br>

Q16\
![Wk8 Q16](MentiImages/w8-10.png)
- Teleportation
- Joystick-based
- Walking-in-place (WIP) with KatVR 360 slidemill
- Walking-in-place (WIP) with HTC Vive HMD and trackers
- Tracking real movement in physical space

<details>
  <summary>Answer</summary>
  Tracking real movement in physical space
</details>
<br>

Q17\
![Wk8 Q17](MentiImages/w8-11.png)
- Teleportation
- Joystick-based
- Walking-in-place (WIP) with KatVR 360 slidemill
- Walking-in-place (WIP) with HTC Vive HMD and trackers
- Tracking real movement in physical space

<details>
  <summary>Answer</summary>
  Walking-in-place (WIP) with HTC Vive HMD and trackers
</details>
<br>

## Week 9
Q1\
Implement a jump action in your Babylon.js scene when the user presses the keyboard spacebar. Which trigger should you use in the ActionManager?
- OnPickTrigger
- OnInteractionEnterTrigger
- OnKeyUpTrigger
- NothingTrigger

<details>
  <summary>Answer</summary>
  OnKeyUpTrigger
</details>
<br>

Q2\
![alt text](MentiImages/w9-1.png)\
Which implementation is the most straightforward, i.e, without reinventing the wheel?
- Behaviors
- ActionManager
- Observables

<details>
  <summary>Answer</summary>
  ActionManager
</details>
<br>

Q3\
In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its proximity to different objects.\
Which implementation is the most straightforward, i.e, without reinventing the wheel?
- Behaviors
- ActionManager
- Observables

<details>
  <summary>Answer</summary>
  Observables
</details>
<br>

Q4\
![alt text](MentiImages/w9-2.png)\
In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its proximity to different objects.\
Which implementation is the most straightforward, i.e, without reinventing the wheel?
- Behaviors
- ActionManager
- Observables

<details>
  <summary>Answer</summary>
  Observables
</details>
<br>

Q5\
![alt text](MentiImages/w9-3.png)\
In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its proximity to different objects.\
Which implementation is the most straightforward, i.e, without reinventing the wheel?
- Behaviors
- ActionManager
- Observables

<details>
  <summary>Answer</summary>
  ActionManager
</details>
<br>

Q6\
![alt text](MentiImages/w9-4.png)\
In your babylon.js, you need to periodically track changes in the position of the dog object and automatically show updates on the HUD based on its proximity to different objects.\
Which implementation is the most straightforward, i.e, without reinventing the wheel?
- Behaviors
- ActionManager
- Observables

<details>
  <summary>Answer</summary>
  Behaviors
</details>
<br>

Q7\
![alt text](MentiImages/w9-5.png)\
In total, how many observers were used here?
- 0
- 1
- 2
- 3
- 4
- 5

<details>
  <summary>Answer</summary>
  2
</details>
<br>

Q8\
![alt text](MentiImages/w9-6.png)\
In total, how many observers were used here?
- 0
- 1
- 2
- 3
- 4
- 5

<details>
  <summary>Answer</summary>
  2
</details>
<br>

Q9\
![alt text](MentiImages/w9-7.png)\
In total, how many observers were used here?
- 0
- 1
- 2
- 3
- 4
- 5

<details>
  <summary>Answer</summary>
  1
</details>
<br>

Q10\
![alt text](MentiImages/w9-8.png)\
What is the mechanics of the following code?
- It adds an Observable to pointerDragBehavior of the sphere
- It adds an Observer to the sphere
- It adds an Observer to onDragObservable of the pointerDragBehavior
- It adds and Observable to the sphere

<details>
  <summary>Answer</summary>
  It adds an Observer to onDragObservable of the pointerDragBehavior
</details>
<br>

Q11\
Which API class in Babylon.js will allow you to easily add UI controls to easily manipulate the position, rotation, and scale of meshes in your scene?
- MultiPointerScaleBehavior
- GizmoManager
- PointerDragBehavior
- WebXRFeaturesManager

<details>
  <summary>Answer</summary>
  GizmoManager
</details>
<br>

Q12\
![alt text](MentiImages/w9-9.png)\
What does ToTeleport do in the following Babylon.js code?\
- Sets the duration of the teleportation animation
- Sets the maximum time to complete the teleportation
- Sets the minimum delay between each teleportation trigger
- Sets the time in to hold the button before teleportation triggers

<details>
  <summary>Answer</summary>
  Sets the time in to hold the button before teleportation triggers
</details>
<br>

## Week 10
Q1\
Which of the following describes immersion from a systems perspective?
- Wide FOV
- Higher spatial presence
- Teleportation feature
- High-fidelity graphics
- Lower cybersickness
- 6-DOF inside-out tracking

<details>
  <summary>Answer</summary>
  Wide FOV
  <br>
  Teleportation feature
  <br>
  High-fidelity graphics
  <br>
  6-DOF inside-out tracking
</details>
<br>

Q2\
**IMAGE REQUIRED**\
Which popular experiential construct(s) of immersion is/are relevant here?
- Flow
- Presence
- Cybersickness

<details>
  <summary>Answer</summary>
  Flow
  <br>
  Cybersickness
</details>
<br>

Q3\
Which of the following implementations will this design translate into?\
![alt text](MentiImages/w10-2.png)
- Constrict the FOV when moving
- Test users using the VRSQ
- Test users using the IPQ
- Create a walking-in-place location feature
- Create a teleportation locomotion feature
- Create a high-fidelity realistic 3D environment

<details>
  <summary>Answer</summary>
  Constrict the FOV when moving
  <br>
  Create a teleportation locomotion feature
</details>
<br>

Q4\
What data collection methods can be appropriate here?
- Let users fill in the IPQ
- Let users fill in the VRSQ
- Let users fill in the FSS
- Perform semi-structured interviews with users
- Create telemetry tracking mechanisms to observe users

<details>
  <summary>Answer</summary>
  Let users fill in the VRSQ
  <br>
  Perform semi-structured interviews with users
  <br>
  Create telemetry tracking mechanisms to observe users
</details>
<br>

Q5\
**IMAGE REQUIRED**\
_IIRC it's something to do with experiencing space_\
Which of the following implementations will this design translate into?
- Constrict the FOV when moving
- Test users using the VRSQ
- Create a zero-gravity arena that simulates physical weightlessness
- Create a walking-in-place location feature
- Create a teleportation locomotion feature
- Create a high-fidelity realistic 3D environment
- Create gamification features to guide users through the experience

<details>
  <summary>Answer</summary>
  Create a zero-gravity arena that simulates physical weightlessness
  <br>
  Create a high-fidelity realistic 3D environment
</details>
<br>

Q6\
**IMAGE REQUIRED**\
_IIRC it's a continuation of Q5_\
What data collection methods can be appropriate here?
- Let users fill in the IPQ
- Let users fill in the VRSQ
- Let users fill in the FSS
- Perform semi-structured interviews with users
- Create telemetry tracking mechanisms to observe users

<details>
  <summary>Answer</summary>
  Let users fill in the IPQ
  <br>
  Perform semi-structured interviews with users
  <br>
  Create telemetry tracking mechanisms to observe users
</details>
<br>

This is for Q7 & Q8\
![alt text](MentiImages/w10-5.png)

Q7\
Which of the following implementations will this design translate into?
- Create a walking-in-place location feature
- Create a teleportation locomotion feature
- Create a high-fidelity realistic 3D environment
- Create a finger-tracked hand gestures to inspect museum artifacts
- Create gamification features to guide users through the experience

<details>
  <summary>Answer</summary>
  Create gamification features to guide users through the experience
</details>
<br>

Q8\
What data collection methods can be appropriate here?
- Let users fill in the IPQ
- Let users fill in the VRSQ
- Let users fill in the FSS
- Perform semi-structured interviews with users
- Create telemetry tracking mechanisms to observe users

<details>
  <summary>Answer</summary>
  Let users fill in the FSS
  <br>
  Perform semi-structured interviews with users
  <br>
  Create telemetry tracking mechanisms to observe users
</details>
<br>

## Week 13 Summary
### Excluding Repeated Week 8 or Week 9 Questions
Q1\
Where should Strava be placed on the RV Continuum?\
![alt text](MentiImages/all-01.png)
- A
- B
- C
- D
- E

<details>
  <summary>Answer</summary>
  B
</details>
<br>

Q2\
Why is Strava not considered to be near the "Real Environment" end of the RV spectrum?
- It has some "Extent of World Knowledge"
- It has some "Reproduction Fidelity"
- It has some "Extent of Presence Metaphor"

<details>
  <summary>Answer</summary>
  A
</details>
<br>

Q3\
Which device sparked the current (21st Century) rise of VR?
- Sega VR
- Oculus Rift DK1
- Google Cardboard
- Oculus Quest
- Meta Quest 2

<details>
  <summary>Answer</summary>
  Oculus Rift DK1
</details>
<br>

Q4\
The 3D models are extremly high quality. What dimension of the RV continuum is this referring to?
- Extent of World Knowledge
- Reproduction Fidelity
- Extent of Presence Metaphor
- Coherency

<details>
  <summary>Answer</summary>
  Reproduction Fidelity
</details>
<br>

Q5\
The stereo optics provide a perception of depth through an LCD display. What dimension of the RV continuum is this referring to?
- Extent of World Knowledge
- Reproduction Fidelity
- Extent of Presence Metaphor
- Coherency

<details>
  <summary>Answer</summary>
  Extent of Presence Metaphor
</details>
<br>

Q6\
For a moment I believed that I was actually 1000ft above ground. What dimension of the RV continuum is this referring to?
- Extent of World Knowledge
- Reproduction Fidelity
- Extent of Presence Metaphor
- Coherency

<details>
  <summary>Answer</summary>
  Coherency
</details>
<br>

Q7\
Which of the following describes immersion from a systems perspective?
- Wide FOV
- Higher spatial presence
- Higher place illusion
- 8K Resolution Display
- Lower cybersickness
- 8-DOF inside out tracking

<details>
  <summary>Answer</summary>
  Wide FOV
  <br>
  8K Resolution Display
  <br>
  8-DOF inside out tracking
</details>
<br>

Q8\
Which of the following describes immersion from an experiential perspective?
- Wide FOV
- Higher spatial presence
- Higher place illusion
- 8K Resolution Display
- Lower cybersickness
- 8-DOF inside out tracking

<details>
  <summary>Answer</summary>
  Higher spatial presence
  <br>
  Higher place illusion
  <br>
  Lower cybersickness
</details>
<br>

Q9\
What is/are the possible famous validated questionnaires to use in the user studies, pertinent to the aims above?\
![alt text](MentiImages/all-02.png)
- Systems Usability Scale (SUS)
- Simulator Sickness Questionnaire (SSQ)
- Flow State Scale (FSS)
- Igroup Presence Questionnaire (IPQ)
- Virtual Reality Sickness Questionnaire (VRSQ)

<details>
  <summary>Answer</summary>
  Flow State Scale (FSS)
</details>
<br>

Q10\
Which of the implementation element(s) below would improve the affordances for interactions in this app?\
![alt text](MentiImages/all-03.png)
- Hand-tracking that allows natural manipulation of objects
- Having objects with clear grooves for gripping
- Haptic feedback when an object correctly fits into place
- Highlighting interactive objects with subtle glow effects
- Optimizing the frame rate and reducing latency
- Having increasing difficulty levels in the puzzles

<details>
  <summary>Answer</summary>
  Hand-tracking that allows natural manipulation of objects
  <br>
  Having objects with clear grooves for gripping
  <br>
  Haptic feedback when an object correctly fits into place
  <br>
  Highlighting interactive objects with subtle glow effects
</details>
<br>

Q11\
Choose the correct statement related to implementation tools.\
- Babylon.js is an open standard for web-based XR applications
- WebXR is an open-source 3D engine for web-based XR applications
- WebXR is only meant for building desktop 3D web applications
- Babylon.js can be used to build WebXR AR applications

<details>
  <summary>Answer</summary>
  Babylon.js can be used to build WebXR AR applications
</details>
<br>

Q12\
What does changing the focal length of the lenses in a HMD affect?\
![alt text](MentiImages/all-04.png)
- The slope of the virtual image
- Distance between the lenses and the physical display
- IPD between the lenses
- Distance between the lenses and the user's eyes
- Vertical FOV
- Horizontal FOV

<details>
  <summary>Answer</summary>
  The slope of the virtual image
  <br>
  Vertical FOV
  <br>
  Horizontal FOV
</details>
<br>

Q13\
Which object is easier for the user to reach out and grab with his/her hands?\
![alt text](MentiImages/all-05.png)
- A
- B
- Both are the same

<details>
  <summary>Answer</summary>
  A
</details>
<br>

Q14\
What effect does using the same projection for both displays (or display partitiions) for both eyes in a VR HMD have?\
- Uniform perception across eyes, hence reduced cybersickness
- The field of view will be enlarged
- Reduced head tracking accurancy, increasing cybersickness
- Reduction in visual anomalies like ghosting or flickering
- None of the answers are correct

<details>
  <summary>Answer</summary>
  None of the answers are correct
</details>
<br>

Q15\
What is the most optimal approach?\
![alt text](MentiImages/all-06.png)
- Model-based
- Image-based

<details>
  <summary>Answer</summary>
  Model-based
</details>
<br>

Q16\
What is the API class in Babylon.js that will allow you to easily use 360 images as the skybox? (Fill in the blank)

[_________]

<details>
  <summary>Hint (Possible Answers)</summary>
  - Skybox
  - VideoDome
  - PhotoDome
  - 360Image
</details>
<br>

<details>
  <summary>Answer</summary>
  PhotoDome
</details>
<br>

Q17\
In total, how many observables did we create?\
![alt text](MentiImages/all-07.png)
- 0
- 1
- 2
- 3
- 4
- 5

<details>
  <summary>Answer</summary>
  0
</details>
<br>

Q18\
The following code allows the sphere to be dragged around...\
![alt text](MentiImages/all-08.png)
- A plane parallel to the direction the player is viewing
- A plane perpendicular to the direction the player is viewing
- In any direction
- A plane parallel to the ground

<details>
  <summary>Answer</summary>
  A plane perpendicular to the direction the player is viewing
</details>
<br>

Q19\
Can you suggest an improvement to the DEBUG CODE to get the position of the sphere only when it is being dragged?\
![alt text](MentiImages/all-09.png)
- add Observer to onDragObservable of pointerDragBehavior to get pos
- add Observer to sphere to get pos
- add Observable to sphere to get pos
- add Observer to scene to get pos

<details>
  <summary>Answer</summary>
  add Observer to onDragObservable of pointerDragBehavior to get pos
</details>
<br>

Q20\
What is the order of the console logs in the following Babylon.js code? (Assume the rest of the code is correct and the scene is set up properly)\
![alt text](MentiImages/all-10.png)
- 2,3,4,1
- 1,2,3,4
- 1,4,3,2
- 4,3,2,1

<details>
  <summary>Answer</summary>
  2,3,4,1
</details>
<br>

Q21\
Which of the following element(s) enhances the experience of flow in a VR game?
- Increasing difficulty of game challenges as the player progresses
- Providing clear goals and feedback
- Improving the realism of the graphics
- Adding more AI-driven characters with human-like behaviors
- None of the answers are correct

<details>
  <summary>Answer</summary>
  Increasing difficulty of game challenges as the player progresses
  <br>
  Providing clear goals and feedback
</details>
<br>

Q22\
In our VR campus exploration game for the next release, a key focus is to reduce cybersickness. Which is/are suitable implementation approaches?\
![alt text](MentiImages/all-11.png)
- Implement progessively challenging levels
- Implement GUI elements to present clear goals at each step
- Real-walking instead of the current joystick-based locomotion
- Reduce the FOV during movement
- Increase visual fidelity of the graphics with physically-based shaders
- Add AI-driven human characters with realistic behaviors

<details>
  <summary>Answer</summary>
  IReal-walking instead of the current joystick-based locomotion
  <br>
  Reduce the FOV during movement
</details>
<br>